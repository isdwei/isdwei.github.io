<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="藤井树不是树">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="藤井树不是树">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="D. Wei">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>藤井树不是树</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">藤井树不是树</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tag"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/Yarn%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%BB%84%E6%88%90%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/Yarn%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%BB%84%E6%88%90%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/" itemprop="url">Yarn的设计组成与基本工作流程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T23:55:36+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="三、Yarn"><a href="#三、Yarn" class="headerlink" title="三、Yarn"></a>三、Yarn</h2><h4 id="1-下一代MapReduce框架的设计思想"><a href="#1-下一代MapReduce框架的设计思想" class="headerlink" title="1. 下一代MapReduce框架的设计思想"></a>1. 下一代MapReduce框架的设计思想</h4><p>Hadoop1.0的弊端：</p>
<ul>
<li>Hadoop MapReduce在可扩展性、资源利用率和多框架支持等方面存在不足。</li>
<li>Hadoop未能将资源调度与应用程序计算的功能分开，造成Hadoop难以支持多种框架。<br><img src="https://img-blog.csdnimg.cn/20200415233740409.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RvbmdfV18=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li>
</ul>
<p>下一代MapReduce的设计思想：将JobTracker的两个主要功能：资源管理和作业控制拆分成两个独立的进程。其中资源管理进程（YARN）与具体应用程序无关，只负责资源的调度，而作业控制进程（ApplicationMaster）则是直接与应用程序相关的模块，每个作业控制进程只负责管理一个作业。<br><img src="https://img-blog.csdnimg.cn/20200415233724151.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RvbmdfV18=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/04/21/Yarn%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%BB%84%E6%88%90%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/apReduce%E7%9A%84%E8%AF%A6%E7%BB%86%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/apReduce%E7%9A%84%E8%AF%A6%E7%BB%86%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/" itemprop="url">MapReduce的详细工作流程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T23:54:24+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h3 id="3-MapReduceTask工作流程"><a href="#3-MapReduceTask工作流程" class="headerlink" title="3. MapReduceTask工作流程"></a>3. MapReduceTask工作流程</h3><p>整理自Hadoop技术内幕</p>
<h4 id="3-1-概述"><a href="#3-1-概述" class="headerlink" title="3.1 概述"></a>3.1 概述</h4><p>MapReduce框架中，一个Task被分为Map和Reduce两个阶段，每个MapTask处理数据集合中的一个split并将产生的数据溢写入本地磁盘；而每个ReduceTask远程通过HTTP以pull的方式拉取相应的中间数据文件，经过合并计算后将结果写入HDFS。</p>
<h4 id="3-2-MapTask"><a href="#3-2-MapTask" class="headerlink" title="3.2 MapTask"></a>3.2 MapTask</h4><p><img src="https://img-blog.csdnimg.cn/20200410005649280.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RvbmdfV18=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>客户端提交任务，规划切片，并将切片文件，程序jar包与任务配置文件上传，Hadoop集群分配节点执行任务；</p>
<ul>
<li><p><strong>Read阶段</strong>：MapTask按InputFormat中定义的方法将数据读取如内存；</p>
</li>
<li><p><strong>Map阶段</strong>：将内存中的数据按map()函数定义的方法处理成K-V对的形式；</p>
</li>
<li><p><strong>Collect阶段</strong>：将K-V对的数据与索引向两个方向写入环形缓冲区（默认100M大小）；</p>
<ul>
<li><p>调用Partitioner.getPartition()获取记录的分区号，再将&lt;key,value,partition&gt;传给MapOutputBuffer.collect()做进一步处理；</p>
</li>
<li><p>MapOutputBuffer内部使用了一个缓冲区暂时存储用户输出数据。几种不同的缓冲区优劣：</p>
<ul>
<li>单向缓冲区：生产者像缓冲区中单向写，写满后一次性写磁盘。性能低，不能同时读写数据。</li>
<li>双缓冲区：一个用于写入数据，一个用于溢写磁盘，交替读写。仍会存在读写等待问题。</li>
<li>环形缓冲区：缓冲区使用率达到一定阈值后便开始溢写磁盘，同时生产者仍可以像不断增加的剩余空间中循环写入数据，读写并行。
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/04/21/apReduce%E7%9A%84%E8%AF%A6%E7%BB%86%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/apReduce%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E2%80%94%E2%80%94%E5%88%87%E7%89%87%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/apReduce%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E2%80%94%E2%80%94%E5%88%87%E7%89%87%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" itemprop="url">MapReduce中的数据输入——切片与数据处理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T23:50:27+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h3 id="2-MapReduce中的数据输入"><a href="#2-MapReduce中的数据输入" class="headerlink" title="2. MapReduce中的数据输入"></a>2. MapReduce中的数据输入</h3><h4 id="2-1-文件切片"><a href="#2-1-文件切片" class="headerlink" title="2.1 文件切片"></a>2.1 文件切片</h4><h5 id="2-1-1-什么是切片"><a href="#2-1-1-什么是切片" class="headerlink" title="2.1.1 什么是切片"></a>2.1.1 什么是切片</h5><p>数据块（Block）：HDFS中数据保存的单位，HDFS在物理上将数据分为一个一个Block管理</p>
<p>数据切片（Split）：在逻辑上对Map任务输入数据的切片。</p>
<h5 id="2-1-2-为什么要切片"><a href="#2-1-2-为什么要切片" class="headerlink" title="2.1.2 为什么要切片"></a>2.1.2 为什么要切片</h5><p>将输入文件分为多片可以并行进行Map阶段的计算，提高Job的运行速度。一份数据切片就会有一个MapTask。</p>
<h5 id="2-1-3-文件的切片机制"><a href="#2-1-3-文件的切片机制" class="headerlink" title="2.1.3 文件的切片机制"></a>2.1.3 文件的切片机制</h5><ul>
<li>简单的按照文件的内容长度切片，切片大小默认为Block的大小（128M）,但每次切片完都会判断剩下的部分是否大于块的1.1倍，不大于1.1倍就归入上一个切片</li>
<li>切片时不会考虑数据集整体，而是单独针对每一份文件切片（默认）</li>
</ul>
<h4 id="2-2-任务提交流程"><a href="#2-2-任务提交流程" class="headerlink" title="2.2 任务提交流程"></a>2.2 任务提交流程</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在客户端Driver中提交任务</span></span><br><span class="line">job.waitForCompletion()</span><br><span class="line">submit();</span><br><span class="line"><span class="comment">// 1建立连接</span></span><br><span class="line">	connect();	</span><br><span class="line">		<span class="comment">// 1）创建提交Job的代理</span></span><br><span class="line">		<span class="keyword">new</span> Cluster(getConfiguration());</span><br><span class="line">			<span class="comment">// （1）判断是本地yarn还是远程</span></span><br><span class="line">			initialize(jobTrackAddr, conf); </span><br><span class="line"><span class="comment">// 2 提交job</span></span><br><span class="line">submitter.submitJobInternal(Job.<span class="keyword">this</span>, cluster)</span><br><span class="line">	<span class="comment">// 1）创建给集群提交数据的Stag路径</span></span><br><span class="line">	Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line">	<span class="comment">// 2）获取jobid ，并创建Job路径</span></span><br><span class="line">	JobID jobId = submitClient.getNewJobID();</span><br><span class="line">	<span class="comment">// 3）拷贝jar包到集群</span></span><br><span class="line">copyAndConfigureFiles(job, submitJobDir);	</span><br><span class="line">	rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line"><span class="comment">// 4）计算切片，生成切片规划文件</span></span><br><span class="line">writeSplits(job, submitJobDir);</span><br><span class="line">		maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line">		input.getSplits(job);</span><br><span class="line">			<span class="keyword">long</span> minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job));</span><br><span class="line">    		<span class="keyword">long</span> maxSize = getMaxSplitSize(job);</span><br><span class="line">			<span class="keyword">for</span> (FileStatus file: files) </span><br><span class="line">                <span class="keyword">long</span> splitSize = computeSplitSize(blockSize, minSize, maxSize);</span><br><span class="line">					<span class="comment">//blockSize与给定的最大值的最小值与给定的Split最小值取最大值</span></span><br><span class="line">					<span class="comment">//最小值默认为1，最大值默认为Long.MAX_VALUE</span></span><br><span class="line">					Math.max(minSize, Math.min(maxSize, blockSize));</span><br><span class="line"><span class="comment">// 5）向Stag路径写XML配置文件</span></span><br><span class="line">writeConf(conf, submitJobFile);</span><br><span class="line">	conf.writeXml(out);</span><br><span class="line"><span class="comment">// 6）提交Job,返回提交状态</span></span><br><span class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/04/21/apReduce%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E2%80%94%E2%80%94%E5%88%87%E7%89%87%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/adoop%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E2%80%94%E2%80%94HDFS%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/adoop%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E2%80%94%E2%80%94HDFS%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81/" itemprop="url">Hadoop文件系统——HDFS读写数据流</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T23:49:12+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="2-HDFS数据流"><a href="#2-HDFS数据流" class="headerlink" title="2. HDFS数据流"></a>2. HDFS数据流</h3><h4 id="2-1-文件读取流程剖析（重要）"><a href="#2-1-文件读取流程剖析（重要）" class="headerlink" title="2.1 文件读取流程剖析（重要）"></a>2.1 文件读取流程剖析（重要）</h4><p><img src="https://img-blog.csdnimg.cn/20200408011130912.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RvbmdfV18=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getFileFromHDFS</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException </span>&#123;</span><br><span class="line">        <span class="comment">// 1 获取文件系统</span></span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">        FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop001:9000"</span>), configuration, <span class="string">"root"</span>);</span><br><span class="line">        <span class="comment">// 2 获取输入流</span></span><br><span class="line">        FSDataInputStream fis = fs.open(<span class="keyword">new</span> Path(<span class="string">"/in.txt"</span>));</span><br><span class="line">        <span class="comment">// 3 获取输出流</span></span><br><span class="line">        FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"in.txt"</span>));</span><br><span class="line">        <span class="comment">// 4 流的对拷</span></span><br><span class="line">        IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line">        <span class="comment">// 5 关闭资源</span></span><br><span class="line">        IOUtils.closeStream(fos);</span><br><span class="line">        IOUtils.closeStream(fis);</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ol>
<li><p><strong>客户端实例化一个FileSystem对象</strong>（其实就是HDFS的DistributedFileSystem实例，DistributedFileSystem继承于FileSystem），调用<strong>DistributedFileSystem.open()方法通过RPC向NameNode请求下载文件</strong>，<strong>NameNode通过查询元数据</strong>，找到<strong>文件开头部分块（第一个块）所有副本所在的DataNode地址</strong>并传给客户端，并且<strong>每个块的副本都基于距离远近排序</strong>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> FSDataInputStream <span class="title">open</span><span class="params">(Path f, <span class="keyword">final</span> <span class="keyword">int</span> bufferSize)</span></span></span><br><span class="line"><span class="function">     <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">   statistics.incrementReadOps(<span class="number">1</span>);</span><br><span class="line">   Path absF = fixRelativePart(f);</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">new</span> FileSystemLinkResolver&lt;FSDataInputStream&gt;() &#123;</span><br><span class="line">     <span class="meta">@Override</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> FSDataInputStream <span class="title">doCall</span><span class="params">(<span class="keyword">final</span> Path p)</span></span></span><br><span class="line"><span class="function">         <span class="keyword">throws</span> IOException, UnresolvedLinkException </span>&#123;</span><br><span class="line">       <span class="keyword">final</span> DFSInputStream dfsis =</span><br><span class="line">         dfs.open(getPathName(p), bufferSize, verifyChecksum);</span><br><span class="line">       <span class="keyword">return</span> dfs.createWrappedInputStream(dfsis);</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="meta">@Override</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> FSDataInputStream <span class="title">next</span><span class="params">(<span class="keyword">final</span> FileSystem fs, <span class="keyword">final</span> Path p)</span></span></span><br><span class="line"><span class="function">         <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> fs.open(p, bufferSize);</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;.resolve(<span class="keyword">this</span>, absF);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>open()方法返回的是一个FSDataInputStream对象（支持文件定位的输入流）给客户端读取数据</strong>。这个FSDataInputStream其实是一个被包装的DFSInputStream对象。</p>
</li>
<li><p>客户端调用这个<strong>输入流的read()方法</strong>。文件开头部分的块的数据节点地址的DFSInputStream随即与这些块最近的数据节点相连接，<strong>数据从数据节点返回客户端</strong>（以Packet为单位来做校验，先在本地缓存，默认buffer为4096位，然后写入目标文件）。当到达块的末端时，DFSInputStream会关闭与数据节点之间的联系，然后为下一个块找到最佳的数据节点。客户端只需要读取一个连续的流，这些对于客户端都是透明的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Copies from one stream to another.</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> in InputStrem to read from</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> out OutputStream to write to</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> buffSize the size of the buffer </span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">copyBytes</span><span class="params">(InputStream in, OutputStream out, <span class="keyword">int</span> buffSize)</span> </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    PrintStream ps = out <span class="keyword">instanceof</span> PrintStream ? (PrintStream)out : <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">byte</span> buf[] = <span class="keyword">new</span> <span class="keyword">byte</span>[buffSize];</span><br><span class="line">    <span class="keyword">int</span> bytesRead = in.read(buf);</span><br><span class="line">    <span class="keyword">while</span> (bytesRead &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      out.write(buf, <span class="number">0</span>, bytesRead);</span><br><span class="line">      <span class="keyword">if</span> ((ps != <span class="keyword">null</span>) &amp;&amp; ps.checkError()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unable to write to output stream."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      bytesRead = in.read(buf);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>客户端从流中读取数据时，块是按DFSInputStream打开与数据节点的新连接的顺序读取的。它也会调用NameNode检索下一组需要的块的位置。一旦完成读取，就会对FSDataInputStream调用close()。</p>
</li>
</ol>
<h4 id="2-2-文件写入流程剖析（重要）"><a href="#2-2-文件写入流程剖析（重要）" class="headerlink" title="2.2 文件写入流程剖析（重要）"></a>2.2 文件写入流程剖析（重要）</h4><p><img src="https://img-blog.csdnimg.cn/20200408011152324.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RvbmdfV18=,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">putFileToHDFS</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException </span>&#123;</span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop001:9000"</span>), configuration, <span class="string">"root"</span>);</span><br><span class="line">	<span class="comment">// 2 创建输入流</span></span><br><span class="line">	FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"in.txt"</span>));</span><br><span class="line">	<span class="comment">// 3 获取输出流</span></span><br><span class="line">	FSDataOutputStream fos = fs.create(<span class="keyword">new</span> Path(<span class="string">"/in.txt"</span>));</span><br><span class="line">	<span class="comment">// 4 流对拷</span></span><br><span class="line">	IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line">	<span class="comment">// 5 关闭资源</span></span><br><span class="line">	IOUtils.closeStream(fos);</span><br><span class="line">	IOUtils.closeStream(fis);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li><p>客户端通过<strong>DistributedFileSystem对象调用create()向NameNode请求上传文件</strong>，<strong>NameNode检查目标文件</strong>是否已存在，父目录是否存在，以及客户端是否有权限创建文件，如果检查通过NameNode就会生成一个新的文件记录<strong>“file.copying”</strong>，并<strong>返回一个文件系统输出流</strong>，否则会向客户端返回一个IOException异常。</p>
</li>
<li><p>客户端将所要上传的文件转换为输出流FSDataOutputStream；</p>
</li>
<li><p>当客户端开始写入文件的时候，<strong>客户端会将文件切分成多个 packets（ 默认64kB ）</strong>，并在<strong>内部以数据队列“data queue（数据队列）”的形式管理这些 packets</strong>，并<strong>向 namenode 申请 blocks</strong>，获取用来存储 replicas 的合适的 datanode 列表，<strong>列表的大小根据 namenode 中 replication 的设定而定，并按距离远近排序</strong>； </p>
</li>
<li><p>开始<strong>以 pipeline（管道）的形式将 packet 写入所有的 replicas 中</strong>。客户端把 packet 以流的方式写入第一个 datanode，该 datanode 把该 packet 存储之后，再将其传递给在此 pipeline 中的下一个 datanode，直到最后一个 datanode，这种<strong>写数据的方式呈流水线的形式</strong>；</p>
<blockquote>
<p> 客户端会根据返回的三个节点和第一个节点建立一个socket连接（只会和第一个节点建立），第一个节点又会和第二个节点建立socket连接，由第二个节点又会和第三个节点建立一个socket连接，这种连接的方式叫Pipeline </p>
</blockquote>
</li>
<li><p>DataNode完成接收block块后，block的metadata（MD5校验码）通过一个心跳将信息汇报给NameNode </p>
</li>
<li><p><strong>最后一个 datanode 成功存储之后会返回一个ack packet（确认包）</strong>，在 pipeline 里传递至客户端，在客户端的开发库内部维护着<strong>“ack queue”</strong>，<strong>成功收到 datanode 返回的ack packet 后会从”data queue”移除相应的 packet；</strong></p>
</li>
<li><p>如果传输过程中，有<strong>某个 datanode 出现了故障，那么当前的 pipeline 会被关闭</strong>，<strong>出现故障的 datanode 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 datanode 中继续 以 pipeline 的形式传输</strong>，同时 <strong>namenode通过心跳检测机制会发现副本数不足，并分配一个新的datanode，保持replicas设定的数量</strong>；</p>
</li>
<li><p>客户端完成数据的写入后，会对数据流调用 close()方法，关闭数据流。并且NameNode若收到所有DataNode的汇报，NameNode会将元数据后的.copying去掉成为正式文件。</p>
</li>
</ol>
<h4 id="2-3-副本节点的选择——机架感知"><a href="#2-3-副本节点的选择——机架感知" class="headerlink" title="2.3 副本节点的选择——机架感知"></a>2.3 副本节点的选择——机架感知</h4><p>第一个副本选择在Client所在节点上，或者随机选一个；<br>第二个副本选择在第一个副本同机架的任一节点；<br>第三个副本选择在同集群另一个机架中的任意节点。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/adoop%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E2%80%94%E2%80%94HDFS%E7%9A%84%E7%BB%84%E7%BB%87%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/adoop%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E2%80%94%E2%80%94HDFS%E7%9A%84%E7%BB%84%E7%BB%87%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/" itemprop="url">Hadoop文件系统——HDFS的组织架构设计</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T23:48:27+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="一、Hadoop-Distributed-FileSystem（HDFS）"><a href="#一、Hadoop-Distributed-FileSystem（HDFS）" class="headerlink" title="一、Hadoop Distributed FileSystem（HDFS）"></a>一、Hadoop Distributed FileSystem（HDFS）</h2><h3 id="1-HDFS的设计"><a href="#1-HDFS的设计" class="headerlink" title="1. HDFS的设计"></a>1. HDFS的设计</h3><p>HDFS时为以<strong>流式数据访问模式</strong>存储<strong>超大文件</strong>而设计的文件系统，在商用硬件集群上运行。</p>
<h4 id="1-1-文件块（Block）"><a href="#1-1-文件块（Block）" class="headerlink" title="1.1 文件块（Block）"></a>1.1 文件块（Block）</h4><p>HDFS以块为单位保存文件，在Hadoop2.x版本中块的大小默认为128M（在hadoop1.x中64M，通过dfs.blocksize规定）。一个小于块大小的文件不会占据整个块空间。</p>
<h5 id="1-1-1-如何确定HDFS中块的大小？"><a href="#1-1-1-如何确定HDFS中块的大小？" class="headerlink" title="1.1.1 如何确定HDFS中块的大小？"></a>1.1.1 如何确定HDFS中块的大小？</h5><p><strong>HDFS中块比磁盘大，目的是减少寻址开销</strong>，从而传输一个由多个块组成的文件的时间就取决于磁盘的传输速率。<br><strong>如果块设计的太大，传输数据时间会增大；如果块设计的太小，会增加寻址时间。</strong></p>
<p><strong>块大小的设计原则：寻址时间为传输时间的1%</strong></p>
<p>目前磁盘的传输速率普遍为100MB/s，若希望寻址时间在10ms以内，那么传输时间为1s，Block大小为100MB，取2的整数次幂得到128MB。</p>
<h5 id="1-1-2-采用块的好处"><a href="#1-1-2-采用块的好处" class="headerlink" title="1.1.2 采用块的好处"></a>1.1.2 采用块的好处</h5><ul>
<li>减少了寻址时间，提高处理大文件的效率</li>
<li>一个文件可以大于网络中任意一个磁盘的容量，不需要存储在同一块磁盘上</li>
<li>简化存储管理（块的大小固定），元数据可以不与块一同储存。</li>
<li>便于提高系统的容错和实用性，方便复制</li>
</ul>
<h4 id="1-2-NameNode，Secondary-NameNode-amp-DataNode"><a href="#1-2-NameNode，Secondary-NameNode-amp-DataNode" class="headerlink" title="1.2 NameNode，Secondary NameNode &amp; DataNode"></a>1.2 NameNode，Secondary NameNode &amp; DataNode</h4><p>HDFS集群有两种节点，以Master-Slave模式运行。</p>
<h5 id="NameNode-amp-Secondary-NameNode"><a href="#NameNode-amp-Secondary-NameNode" class="headerlink" title="NameNode&amp;Secondary NameNode"></a>NameNode&amp;Secondary NameNode</h5><p><strong>NameNode作用：管理整个文件系统的命名空间；配置副本策略；管理Block的映射信息；处理客户端读写请求</strong><br><strong>SeconaryNameNode作用：复制NameNode，定期合并Fsimage，Edits；辅助恢复NameNode</strong></p>
<blockquote>
<p>NameNode中并不保留Block的位置信息，而是DataNode启动后定期汇报。</p>
</blockquote>
<p><strong>工作机制</strong>：</p>
<ul>
<li>第一阶段：NameNode启动<ul>
<li>第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接<strong>加载编辑日志和镜像文件到内存</strong>。</li>
<li>客户端对元数据进行增删改的请求：<strong>NameNode先记录操作日志，更新滚动日志再内存中对数据进行增删改。</strong></li>
</ul>
</li>
<li>第二阶段：Secondary NameNode工作<ul>
<li>Secondary NameNode询问NameNode是否需要CheckPoint，返回NameNode是否检查结果。（         <strong>触发CheckPoint需要满足两个条件中的任意一个：1小时时间到和每隔一分种检查Edits中操作次数是否达到100万</strong>）  </li>
<li>若需要CheckPoint则请求执行：<ul>
<li>NameNode<strong>滚动正在写的Edits日志，生成一个空的edits.inprogress</strong>，将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode；</li>
<li>Secondary NameNode<strong>加载编辑日志和镜像文件到内存，并合并，生成新的镜像文件</strong>fsimage.chkpoint。</li>
<li>拷贝fsimage.chkpoint到NameNode，NameNode将fsimage.chkpoint重新命名成fsimage。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Secondary NameNode恢复NameNode的方法：</p>
<ul>
<li>直接拷贝</li>
<li>使用<code>hdfs namenode -importCheckpoint</code>启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中  </li>
</ul>
<p><strong>集群安全模式：</strong></p>
<ul>
<li>NameNode启动时，首先将镜像文件（Fsimage）载入内存，并执行编辑日志（Edits）中的各项操作。一旦在内存中成功建立文件系统元数据的映像，则创建一个新的Fsimage文件和一个空的编辑日志。此时，NameNode开始监听DataNode请求。<strong>这个过程期间，NameNode一直运行在安全模式，即NameNode的文件系统对于客户端来说是只读的。</strong></li>
<li>系统中的<strong>数据块的位置并不是由NameNode维护的，而是以块列表的形式存储在DataNode中</strong>。在系统的正常操作期间，NameNode会在内存中保留所有块位置的映射信息。在安全模式下，各个DataNode会向NameNode发送最新的块列表信息，NameNode了解到足够多的块位置信息之后，即可高效运行文件系统。</li>
<li>如果<strong>满足“最小副本条件”</strong>，<strong>NameNode会在30秒钟之后就退出安全模式</strong>。所谓的最小副本条件指的是在整个文件系统中99.9%的块满足最小副本级别（默认值：dfs.replication.min=1）。在<strong>启动一个刚刚格式化的HDFS集群时，因为系统中还没有任何块，所以NameNode不会进入安全模式</strong>。</li>
</ul>
<h5 id="DataNode："><a href="#DataNode：" class="headerlink" title="DataNode："></a>DataNode：</h5><p><strong>作用：储存实际数据块；执行读写操作</strong></p>
<ul>
<li>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，<strong>一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</strong>DataNode会<strong>周期性检验文件的校验和是否与创建时相同以保证文件的正确性；</strong></li>
<li><strong>DataNode启动后向NameNode注册</strong>，通过后，<strong>周期性（1小时）的向NameNode上报所有的块信息</strong>。</li>
<li><strong>心跳是每3秒一次</strong>，<strong>心跳返回结果带有NameNode给该DataNode的命令</strong>如复制块数据到另一台机器，或删除某个数据块。<strong>如果超过10分钟（默认超时时长10分钟+30秒）没有收到某个DataNode的心跳，则认为该节点不可用</strong>。</li>
<li>集群运行中可以安全加入和退出一些机器。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/%E7%BB%86%E8%A7%A3%E6%9E%90%EF%BC%9Amysql%E5%AE%9E%E7%8E%B0%E5%88%86%E7%BB%84%E6%9F%A5%E8%AF%A2%E6%AF%8F%E4%B8%AA%E7%8F%AD%E7%BA%A7%E7%9A%84%E5%89%8D%E4%B8%89%E5%90%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/%E7%BB%86%E8%A7%A3%E6%9E%90%EF%BC%9Amysql%E5%AE%9E%E7%8E%B0%E5%88%86%E7%BB%84%E6%9F%A5%E8%AF%A2%E6%AF%8F%E4%B8%AA%E7%8F%AD%E7%BA%A7%E7%9A%84%E5%89%8D%E4%B8%89%E5%90%8D/" itemprop="url">详细解析：mysql实现分组查询每个班级的前三名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T23:47:28+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="8-2-mysql实现分组查询每个班级的前三名"><a href="#8-2-mysql实现分组查询每个班级的前三名" class="headerlink" title="8.2 mysql实现分组查询每个班级的前三名"></a>8.2 mysql实现分组查询每个班级的前三名</h4><p><strong>先上答案</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.class,a.score <span class="keyword">from</span> student a </span><br><span class="line"><span class="keyword">where</span> </span><br><span class="line">(<span class="keyword">select</span> </span><br><span class="line"> <span class="keyword">count</span>(*) </span><br><span class="line"> <span class="keyword">from</span> </span><br><span class="line"> student </span><br><span class="line"> <span class="keyword">where</span> a.class=<span class="keyword">class</span> <span class="keyword">and</span> a.score&lt;score)</span><br><span class="line"> &lt;<span class="number">3</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> </span><br><span class="line">a.class, a.score </span><br><span class="line"><span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>

<p><strong>解析：</strong></p>
<p>对于上面的sql语句，将其拆分为两部分：</p>
<p>主查询：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.class,a.score <span class="keyword">from</span> student a </span><br><span class="line"><span class="keyword">where</span> </span><br><span class="line">  condition</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> a.class, a.score <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>

<p>主查询很好理解，对于a中的每一行，只要它满足condition条件，那就把它作为结果，排序输出。</p>
<p>那么什么样的一样可以满足condition条件呢？</p>
<p>子查询 condition：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="keyword">select</span> <span class="keyword">count</span>(*)  <span class="keyword">from</span>  student  <span class="keyword">where</span> a.class=<span class="keyword">class</span> <span class="keyword">and</span> a.score&lt;score) &lt;<span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>可以看到，在子查询中，对于a中的每一行，记为传入行，都与student表中的每一行（记为内部行）进行一次比较，有两个条件：</p>
<ul>
<li>传入行和传出行类别相同；</li>
<li>传入行的分数小于内部行的分数。</li>
</ul>
<p>当这两个条件满足，就说明这个表中这一条内部行的分数比传入行大。</p>
<p>子查询的输出为count(*)，也就是要统计满足上述两个条件的行数的条目数。有N条满足，就说明这个表中有N条数据大于该传入行，也就是传入行的分数在这一类中排第N+1。</p>
<p>那么再加一个限定条件&lt;3，也就是取前三名。</p>
<p>这样结果就显然易见了。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/Kafka%EF%BC%9A%E6%95%B4%E7%90%86%E7%9A%84%E4%B8%80%E4%BA%9B%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/Kafka%EF%BC%9A%E6%95%B4%E7%90%86%E7%9A%84%E4%B8%80%E4%BA%9B%E9%9D%A2%E8%AF%95%E9%A2%98/" itemprop="url">Kafka知识点总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T22:56:08+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h4 id="1-Kafka-中的-ISR-InSyncRepli-、-OSR-OutSyncRepli-、-AR-AllRepli-代表什么？"><a href="#1-Kafka-中的-ISR-InSyncRepli-、-OSR-OutSyncRepli-、-AR-AllRepli-代表什么？" class="headerlink" title="1. Kafka 中的 ISR(InSyncRepli)、 OSR(OutSyncRepli)、 AR(AllRepli)代表什么？"></a>1. Kafka 中的 ISR(InSyncRepli)、 OSR(OutSyncRepli)、 AR(AllRepli)代表什么？</h4><p><strong>ISR</strong>：In-Sync Replicas 副本同步队列<br><strong>AR</strong>：Assigned Replicas 所有副本<br>ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。</p>
<h4 id="2-Kafka-中的-HW、-LEO-等分别代表什么？"><a href="#2-Kafka-中的-HW、-LEO-等分别代表什么？" class="headerlink" title="2.Kafka 中的 HW、 LEO 等分别代表什么？"></a>2.Kafka 中的 HW、 LEO 等分别代表什么？</h4><p><strong>LEO（Log End Offset）</strong>：每个副本的最后一个offset<br><strong>HW（High Watermark）</strong>：所有副本的最小LEO</p>
<p>follower故障时：follower会被踢出isr，恢复后，follower读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步，等follower的LEO大于等于该partition的HW后，就可以重新加入isr。</p>
<p>leader故障时：leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的，  数据一致性， 其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader同步数据。  </p>
<h4 id="3-Kafka-中是怎么体现消息顺序性的？"><a href="#3-Kafka-中是怎么体现消息顺序性的？" class="headerlink" title="3. Kafka 中是怎么体现消息顺序性的？"></a><strong>3. Kafka 中是怎么体现消息顺序性的？</strong></h4><p>kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。<br>整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1. </p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/04/21/Kafka%EF%BC%9A%E6%95%B4%E7%90%86%E7%9A%84%E4%B8%80%E4%BA%9B%E9%9D%A2%E8%AF%95%E9%A2%98/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%EF%BC%9A%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5%E5%8D%8F%E8%B0%83%E5%99%A8%E4%B8%8Eoffset/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%EF%BC%9A%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5%E5%8D%8F%E8%B0%83%E5%99%A8%E4%B8%8Eoffset/" itemprop="url">Kafka消费者：分区分配策略、协调器、offset</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T22:56:07+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="Kafka消费者：分区分配策略、协调器、offset"><a href="#Kafka消费者：分区分配策略、协调器、offset" class="headerlink" title="Kafka消费者：分区分配策略、协调器、offset"></a>Kafka消费者：分区分配策略、协调器、offset</h2><h3 id="1-消费方式-Push-vs-Pull"><a href="#1-消费方式-Push-vs-Pull" class="headerlink" title="1. 消费方式 Push vs Pull　　"></a>1. 消费方式 Push vs Pull　　</h3><p>作为一个消息系统，Kafka遵循了传统的方式，选择由Producer向broker push消息并由Consumer从broker pull消息。一些logging-centric system，比如Facebook的Scribe和Cloudera的Flume，采用push模式。事实上，push模式和pull模式各有优劣。 push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。<strong>push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息</strong>。 对于Kafka而言，pull模式更合适。<strong>pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义</strong>。 <strong>pull模式的不足在于，如果Kafka没有数据，消费者可能会陷入循环中，一直返回空数据</strong>。</p>
<h3 id="2-分区分配策略"><a href="#2-分区分配策略" class="headerlink" title="2. 分区分配策略"></a>2. 分区分配策略</h3><p>Kafka保证同一Consumer Group中只有一个Consumer会消费某条消息，实际上，Kafka保证的是稳定状态下每一个Consumer实例只会消费某一个或多个特定Partition的数据，而某个Partition的数据只会被某一个特定的Consumer实例所消费。也就是说Kafka对消息的分配是以Partition为单位分配的，而非以每一条消息作为分配单元。这样设计的劣势是无法保证同一个Consumer Group里的Consumer均匀消费数据，优势是每个Consumer不用都跟大量的Broker通信，减少通信开销，同时也降低了分配难度，实现也更简单。另外，因为同一个Partition里的数据是有序的，这种设计可以保证每个Partition里的数据可以被有序消费。</p>
<p>一个Consumer Group中的多个consumer是如何消费不同的partition？</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/04/21/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%EF%BC%9A%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5%E5%8D%8F%E8%B0%83%E5%99%A8%E4%B8%8Eoffset/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%AD%96%E7%95%A5%E4%B8%8E%E5%B9%82%E7%AD%89%E6%80%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%AD%96%E7%95%A5%E4%B8%8E%E5%B9%82%E7%AD%89%E6%80%A7/" itemprop="url">Kafka生产者：数据可靠性策略与幂等性</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T22:56:06+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="Kafka生产者：数据可靠性策略与幂等性"><a href="#Kafka生产者：数据可靠性策略与幂等性" class="headerlink" title="Kafka生产者：数据可靠性策略与幂等性"></a>Kafka生产者：数据可靠性策略与幂等性</h2><h3 id="1-Kafka生产者发送消息的过程"><a href="#1-Kafka生产者发送消息的过程" class="headerlink" title="1. Kafka生产者发送消息的过程"></a>1. Kafka生产者发送消息的过程</h3><ul>
<li><strong>Kafka 会将发送消息包装为 ProducerRecord 对象</strong>， ProducerRecord 对象包含了目标主题和要发送的内容，同时还可以指定键和分区。在发送 ProducerRecord 对象前，生产者会<strong>先把键和值对象序列化成字节数组</strong>，这样它们才能够在网络上传输。</li>
<li>接下来，<strong>数据被传给分区器</strong>。如果之前已经在 ProducerRecord 对象里指定了分区，那么分区器就不会再做任何事情。如果没有指定分区 ，那么分区器会<strong>根据 ProducerRecord 对象的键来选择一个分区</strong>，紧接着，这条记录被<strong>添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上</strong>。有一个独立的线程负责把这些记录批次发送到相应的 broker 上。</li>
<li><strong>服务器在收到这些消息时会返回一个响应</strong>。如果消息成功写入 Kafka，就<strong>返回一个 RecordMetaData 对象</strong>，它<strong>包含了主题和分区信息，以及记录在分区里的偏移量</strong>。如果写入失败，则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，如果达到指定的重试次数后还没有成功，则直接抛出异常，不再重试。</li>
</ul>
<h3 id="2-分区策略"><a href="#2-分区策略" class="headerlink" title="2. 分区策略"></a>2. 分区策略</h3>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/04/21/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%AD%96%E7%95%A5%E4%B8%8E%E5%B9%82%E7%AD%89%E6%80%A7/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/21/Kafka%E7%9A%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E6%9E%B6%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="D. Wei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="藤井树不是树">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/21/Kafka%E7%9A%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E6%9E%B6%E6%9E%84/" itemprop="url">Kafka简介与架构</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-21T22:56:05+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="一、Kafka简介与架构"><a href="#一、Kafka简介与架构" class="headerlink" title="一、Kafka简介与架构"></a>一、Kafka简介与架构</h2><h3 id="1-kafka定义"><a href="#1-kafka定义" class="headerlink" title="1. kafka定义"></a>1. kafka定义</h3><p>Kafka是一个基于发布订阅模式的分布式消息队列，它具有以下特点：</p>
<ul>
<li>支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；</li>
<li>支持数据离线和实时处理；</li>
<li>能保证消息的可靠性投递；</li>
<li>支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错，时间效率O(1)；</li>
<li>高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。</li>
<li>支持在线水平扩展</li>
</ul>
<h3 id="2-消息队列的优点"><a href="#2-消息队列的优点" class="headerlink" title="2. 消息队列的优点"></a>2. 消息队列的优点</h3><ul>
<li><strong>解耦：</strong>两边数据处理过程独立，可任意修改，只要遵从相同的接口约束</li>
<li><strong>可恢复性：</strong>系统的一部分组件失效时，不会影响到整个系统。即使一个处理消息的进程挂掉，加入队列中的消息仍可在系统恢复后处理</li>
<li><strong>缓冲：</strong>控制优化数据流经过系统的速度，解决生产消费速度不一致的问题</li>
<li><strong>削峰平谷：</strong>访问量剧增的情况可以避免系统因超负荷的请求而崩溃</li>
<li><strong>异步通信：</strong>提供了异步处理机制</li>
</ul>
<h3 id="3-Kafka与其他消息队列的对比"><a href="#3-Kafka与其他消息队列的对比" class="headerlink" title="3. Kafka与其他消息队列的对比"></a>3. Kafka与其他消息队列的对比</h3>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/04/21/Kafka%E7%9A%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E6%9E%B6%E6%9E%84/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">&lt;i class&#x3D;&quot;fa fa-angle-right&quot;&gt;&lt;&#x2F;i&gt;</a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">D. Wei</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7Carchive">
              
                  <span class="site-state-item-count">26</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/isdwei" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:dwei96@mail.ustc.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">D. Wei</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
